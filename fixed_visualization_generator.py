#!/usr/bin/env python3
"""
ä¿®å¤å·¨å¤§åœ†ç¯é—®é¢˜çš„å¯è§†åŒ–ç”Ÿæˆå™¨
å®ç°ï¼šLCCæå–ã€è¾¹æƒé‡Quantileè¿‡æ»¤(0.98)ã€è‡ªé€‚åº”kå‚æ•°å¸ƒå±€
"""

import os
import sys
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import networkx as nx
from collections import defaultdict, Counter
from tqdm import tqdm
from datetime import datetime
import math


def extract_largest_connected_component(graph):
    """
    å¼ºåˆ¶æå–å›¾çš„æœ€å¤§è¿é€šåˆ†é‡(LCC)è¿›è¡Œç»˜å›¾
    è§£å†³å›¾è¿‡äºç¢è£‚å¯¼è‡´çš„å·¨å¤§åœ†ç¯é—®é¢˜
    """
    print("ğŸ”— å¼ºåˆ¶æå–æœ€å¤§è¿é€šåˆ†é‡(LCC)...")
    
    if graph.number_of_nodes() == 0:
        return graph
    
    # æ‰¾åˆ°æ‰€æœ‰è¿é€šåˆ†é‡
    components = list(nx.connected_components(graph))
    
    if not components:
        return nx.Graph()
    
    # è·å–æœ€å¤§è¿é€šåˆ†é‡
    largest_component = max(components, key=len)
    lcc = graph.subgraph(largest_component).copy()
    
    print(f"   ğŸ“Š åŸå›¾: {graph.number_of_nodes()} èŠ‚ç‚¹, {graph.number_of_edges()} è¾¹")
    print(f"   ğŸ“Š LCC: {lcc.number_of_nodes()} èŠ‚ç‚¹, {lcc.number_of_edges()} è¾¹")
    print(f"   ğŸ“Š ç§»é™¤å­¤ç«‹èŠ‚ç‚¹: {graph.number_of_nodes() - lcc.number_of_nodes()}")
    print(f"   ğŸ“Š è¿é€šåˆ†é‡æ•°: {len(components)} â†’ 1")
    
    return lcc


def apply_quantile_edge_filtering(graph, quantile_threshold=0.98):
    """
    åº”ç”¨æ›´ä¸¥æ ¼çš„è¾¹æƒé‡Quantileè¿‡æ»¤(0.98)
    ç¡®ä¿åªæœ‰æœ€å¼ºçš„å…³è”è¢«ä¿ç•™
    """
    print(f"ğŸ“Š åº”ç”¨ä¸¥æ ¼è¾¹æƒé‡è¿‡æ»¤ (Quantile {quantile_threshold})...")
    
    if graph.number_of_edges() == 0:
        return graph
    
    # è·å–æ‰€æœ‰è¾¹æƒé‡
    edge_weights = []
    for u, v, data in graph.edges(data=True):
        weight = data.get('weight', data.get('semantic_weight', 1.0))
        edge_weights.append(((u, v), weight))
    
    # è®¡ç®—é˜ˆå€¼
    weights_only = [w for _, w in edge_weights]
    threshold = np.percentile(weights_only, quantile_threshold * 100)
    
    # åˆ›å»ºè¿‡æ»¤åçš„å›¾
    filtered_graph = nx.Graph()
    filtered_graph.add_nodes_from(graph.nodes(data=True))
    
    edges_kept = 0
    for (u, v), weight in edge_weights:
        if weight >= threshold:
            filtered_graph.add_edge(u, v, **graph[u][v])
            edges_kept += 1
    
    print(f"   ğŸ“Š æƒé‡é˜ˆå€¼: {threshold:.4f}")
    print(f"   ğŸ“Š ä¿ç•™è¾¹æ•°: {edges_kept} / {len(edge_weights)} ({edges_kept/len(edge_weights)*100:.1f}%)")
    
    return filtered_graph


def compute_adaptive_spring_layout(graph, seed=42):
    """
    è®¡ç®—è‡ªé€‚åº”springå¸ƒå±€ï¼Œkå‚æ•°æ ¹æ®èŠ‚ç‚¹æ•°è‡ªåŠ¨è°ƒæ•´
    å…¬å¼: k = 1 / sqrt(n)
    """
    print("ğŸ¯ è®¡ç®—è‡ªé€‚åº”springå¸ƒå±€...")
    
    if graph.number_of_nodes() == 0:
        return {}
    
    n_nodes = graph.number_of_nodes()
    k_param = 1.0 / math.sqrt(n_nodes)
    
    print(f"   ğŸ“Š èŠ‚ç‚¹æ•°: {n_nodes}")
    print(f"   ğŸ“Š è‡ªé€‚åº”kå‚æ•°: {k_param:.4f} (= 1/âˆš{n_nodes})")
    
    # è®¡ç®—å¸ƒå±€
    with tqdm(total=1000, desc="ğŸ¯ Springå¸ƒå±€è®¡ç®—", unit="iter") as pbar:
        pos = nx.spring_layout(
            graph,
            k=k_param,
            iterations=1000,
            seed=seed,
            weight='weight'
        )
        pbar.update(1000)
    
    print(f"   âœ… å¸ƒå±€è®¡ç®—å®Œæˆ: {len(pos)} ä¸ªèŠ‚ç‚¹ä½ç½®")
    return pos


def generate_fixed_visualization(graph, output_path, title="Fixed Co-occurrence Network", 
                                seed=42, quantile_threshold=0.98):
    """
    ç”Ÿæˆä¿®å¤åçš„å¯è§†åŒ–ï¼Œè§£å†³å·¨å¤§åœ†ç¯é—®é¢˜
    
    ä¿®å¤æªæ–½ï¼š
    1. å¼ºåˆ¶LCCæå–
    2. ä¸¥æ ¼è¾¹æƒé‡è¿‡æ»¤(0.98)
    3. è‡ªé€‚åº”kå‚æ•°å¸ƒå±€
    """
    print(f"\nğŸ¨ ç”Ÿæˆä¿®å¤åçš„å¯è§†åŒ–: {title}")
    print("=" * 60)
    
    if graph.number_of_nodes() == 0:
        print("   âš ï¸ ç©ºå›¾ï¼Œè·³è¿‡å¯è§†åŒ–")
        return None
    
    # æ­¥éª¤1: åº”ç”¨ä¸¥æ ¼è¾¹æƒé‡è¿‡æ»¤
    filtered_graph = apply_quantile_edge_filtering(graph, quantile_threshold)
    
    # æ­¥éª¤2: å¼ºåˆ¶æå–LCC
    lcc_graph = extract_largest_connected_component(filtered_graph)
    
    if lcc_graph.number_of_nodes() == 0:
        print("   âš ï¸ LCCä¸ºç©ºï¼Œè·³è¿‡å¯è§†åŒ–")
        return None
    
    # æ­¥éª¤3: è®¡ç®—è‡ªé€‚åº”å¸ƒå±€
    positions = compute_adaptive_spring_layout(lcc_graph, seed)
    
    # æ­¥éª¤4: ç¤¾åŒºæ£€æµ‹ï¼ˆç”¨äºç€è‰²ï¼‰
    print("ğŸ˜ï¸ æ£€æµ‹ç¤¾åŒºç»“æ„...")
    try:
        import community as community_louvain
        communities = community_louvain.best_partition(lcc_graph, weight='weight', random_state=seed)
    except:
        communities = {node: 0 for node in lcc_graph.nodes()}
    
    community_count = len(set(communities.values()))
    print(f"   ğŸ“Š æ£€æµ‹åˆ°ç¤¾åŒºæ•°: {community_count}")
    
    # æ­¥éª¤5: æ ¸å¿ƒ-å¤–å›´è¯†åˆ«
    print("ğŸ¯ è¯†åˆ«æ ¸å¿ƒ-å¤–å›´ç»“æ„...")
    degrees = dict(lcc_graph.degree())
    sorted_nodes = sorted(degrees.items(), key=lambda x: x[1], reverse=True)
    n_core = max(1, min(20, len(sorted_nodes) // 4))  # æœ€å¤š20ä¸ªæ ¸å¿ƒèŠ‚ç‚¹
    core_nodes = set(node for node, _ in sorted_nodes[:n_core])
    
    print(f"   ğŸ“Š æ ¸å¿ƒèŠ‚ç‚¹æ•°: {n_core} / {len(sorted_nodes)}")
    
    # æ­¥éª¤6: ç”Ÿæˆå¯è§†åŒ–
    print("ğŸ¨ ç»˜åˆ¶ç½‘ç»œå›¾...")
    
    plt.style.use('default')
    fig, ax = plt.subplots(1, 1, figsize=(16, 12))
    ax.set_facecolor('white')
    
    # å‡†å¤‡èŠ‚ç‚¹å±æ€§
    node_colors = []
    node_sizes = []
    node_shapes_core = []
    node_shapes_periphery = []
    
    # ç¤¾åŒºé¢œè‰²
    unique_communities = sorted(set(communities.values()))
    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_communities)))
    community_colors = {comm: colors[i % len(colors)] for i, comm in enumerate(unique_communities)}
    
    # å¤„ç†æ¯ä¸ªèŠ‚ç‚¹
    for node in lcc_graph.nodes():
        # ç¤¾åŒºé¢œè‰²
        comm_id = communities.get(node, 0)
        color = community_colors.get(comm_id, 'lightblue')
        node_colors.append(color)
        
        # èŠ‚ç‚¹å¤§å°ï¼ˆåŸºäºåº¦æ•°ï¼‰
        degree = degrees.get(node, 1)
        max_degree = max(degrees.values()) if degrees else 1
        size = 100 + 400 * (degree / max_degree)
        node_sizes.append(size)
        
        # æŒ‰è§’è‰²åˆ†ç»„
        if node in core_nodes:
            node_shapes_core.append(node)
        else:
            node_shapes_periphery.append(node)
    
    # ç»˜åˆ¶è¾¹ï¼ˆè½»ç°è‰²ï¼Œä½é€æ˜åº¦ï¼‰
    if lcc_graph.number_of_edges() > 0:
        nx.draw_networkx_edges(
            lcc_graph, positions,
            width=0.5,
            alpha=0.2,
            edge_color='lightgray',
            ax=ax
        )
    
    # ç»˜åˆ¶å¤–å›´èŠ‚ç‚¹ï¼ˆåœ†å½¢ï¼‰
    if node_shapes_periphery:
        periphery_colors = [community_colors.get(communities.get(node, 0), 'lightblue') 
                          for node in node_shapes_periphery]
        periphery_sizes = [node_sizes[list(lcc_graph.nodes()).index(node)] 
                         for node in node_shapes_periphery]
        nx.draw_networkx_nodes(
            lcc_graph, positions,
            nodelist=node_shapes_periphery,
            node_color=periphery_colors,
            node_size=periphery_sizes,
            node_shape='o',
            alpha=0.8,
            edgecolors='gray',
            linewidths=0.5,
            ax=ax
        )
    
    # ç»˜åˆ¶æ ¸å¿ƒèŠ‚ç‚¹ï¼ˆä¸‰è§’å½¢ï¼‰
    if node_shapes_core:
        core_colors = [community_colors.get(communities.get(node, 0), 'lightblue') 
                      for node in node_shapes_core]
        core_sizes = [node_sizes[list(lcc_graph.nodes()).index(node)] 
                     for node in node_shapes_core]
        nx.draw_networkx_nodes(
            lcc_graph, positions,
            nodelist=node_shapes_core,
            node_color=core_colors,
            node_size=core_sizes,
            node_shape='^',
            alpha=0.9,
            edgecolors='black',
            linewidths=1.0,
            ax=ax
        )
    
    # æ·»åŠ é€‰æ‹©æ€§æ ‡ç­¾ï¼ˆä»…æ ¸å¿ƒèŠ‚ç‚¹ï¼‰
    if node_shapes_core:
        labels_to_draw = {}
        for node in node_shapes_core[:10]:  # æœ€å¤š10ä¸ªæ ‡ç­¾
            label = str(node)[:15] + "..." if len(str(node)) > 15 else str(node)
            labels_to_draw[node] = label
        
        if labels_to_draw:
            nx.draw_networkx_labels(
                lcc_graph, positions,
                labels_to_draw,
                font_size=8,
                font_weight='bold',
                font_color='black',
                ax=ax
            )
    
    # æ ‡é¢˜å’Œç»Ÿè®¡ä¿¡æ¯
    density = nx.density(lcc_graph)
    ax.set_title(
        f'{title}\n'
        f'LCC: N={lcc_graph.number_of_nodes()}, E={lcc_graph.number_of_edges()}, '
        f'Density={density:.4f}, Communities={community_count}\n'
        f'Core={len(node_shapes_core)}, Quantile={quantile_threshold}, k={1.0/math.sqrt(lcc_graph.number_of_nodes()):.4f}, Seed={seed}',
        fontsize=14, fontweight='bold', pad=20
    )
    
    # å›¾ä¾‹
    legend_elements = []
    
    # ç¤¾åŒºå›¾ä¾‹ï¼ˆæœ€å¤šæ˜¾ç¤º8ä¸ªï¼‰
    for i, (comm_id, color) in enumerate(list(community_colors.items())[:8]):
        comm_size = sum(1 for c in communities.values() if c == comm_id)
        legend_elements.append(patches.Patch(color=color, label=f'Community {comm_id} (n={comm_size})'))
    
    if len(unique_communities) > 8:
        other_size = sum(1 for c in communities.values() if c not in list(community_colors.keys())[:8])
        legend_elements.append(patches.Patch(color='lightgray', label=f'Other (n={other_size})'))
    
    # å½¢çŠ¶å›¾ä¾‹
    legend_elements.append(patches.Patch(color='white', label=''))  # åˆ†éš”ç¬¦
    legend_elements.append(plt.Line2D([0], [0], marker='^', color='w', 
                                    markerfacecolor='gray', markersize=10, label='Core nodes'))
    legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', 
                                    markerfacecolor='gray', markersize=8, label='Periphery nodes'))
    
    # æ–¹æ³•å›¾ä¾‹
    legend_elements.append(patches.Patch(color='white', label=''))  # åˆ†éš”ç¬¦
    legend_elements.append(patches.Patch(color='lightgray', label=f'LCC Extraction: Yes'))
    legend_elements.append(patches.Patch(color='lightgray', label=f'Edge Filter: Q{quantile_threshold}'))
    legend_elements.append(patches.Patch(color='lightgray', label=f'Adaptive k: 1/âˆšn'))
    
    ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.02, 1), 
            frameon=True, fancybox=True, shadow=True)
    
    ax.axis('off')
    plt.tight_layout()
    
    # ä¿å­˜é«˜åˆ†è¾¨ç‡å›¾åƒ
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"   âœ… ä¿å­˜: {output_path}")
    print(f"   ğŸ“Š æœ€ç»ˆå›¾: {lcc_graph.number_of_nodes()} èŠ‚ç‚¹, {lcc_graph.number_of_edges()} è¾¹")
    print(f"   ğŸ“Š å¯†åº¦: {density:.6f}")
    print(f"   ğŸ“Š ç¤¾åŒºæ•°: {community_count}")
    
    return output_path


def test_fixed_visualization():
    """æµ‹è¯•ä¿®å¤åçš„å¯è§†åŒ–ç”Ÿæˆ"""
    print("ğŸ”§ æµ‹è¯•ä¿®å¤åçš„å¯è§†åŒ–ç”Ÿæˆ")
    print("ä¿®å¤æªæ–½: LCCæå– + è¾¹æƒé‡è¿‡æ»¤(0.98) + è‡ªé€‚åº”kå‚æ•°")
    print()
    
    # å¯¼å…¥ä¸»ç¨‹åº
    try:
        from complete_usage_guide import ResearchPipelineCLI
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return
    
    # è®¾ç½®æµ‹è¯•å‚æ•° - use relative paths for portability
    input_dir = "test_input"
    output_dir = "test_output"
    
    if not os.path.exists(input_dir):
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆ›å»ºç®¡çº¿å®ä¾‹å¹¶è¿è¡Œåˆ°å›¾æ„å»º
    cli = ResearchPipelineCLI()
    cli.input_directory = input_dir
    cli.output_dir = output_dir
    
    # æ‰«æè¾“å…¥æ–‡ä»¶
    cli.input_files = []
    valid_extensions = {'.json', '.txt', '.md'}
    for root, dirs, files in os.walk(input_dir):
        for file in files:
            file_path = os.path.join(root, file)
            file_ext = os.path.splitext(file)[1].lower()
            if file_ext in valid_extensions:
                cli.input_files.append(file_path)
    
    print(f"ğŸ“Š æ‰¾åˆ°æ–‡ä»¶: {len(cli.input_files)} ä¸ª")
    
    # è®¾ç½®ç®¡çº¿çŠ¶æ€
    cli.pipeline_state = {
        'data_loaded': True,
        'text_cleaned': False,
        'phrases_constructed': False,
        'global_graph_built': False,
        'subgraphs_activated': False,
        'results_exported': False
    }
    
    try:
        # æ‰§è¡Œç®¡çº¿åˆ°å›¾æ„å»º
        print("\n=== æ‰§è¡Œç®¡çº¿åˆ°å›¾æ„å»º ===")
        cli.clean_and_normalize_text()
        cli.extract_tokens_and_phrases()
        cli.build_global_graph()
        
        # è·å–æ„å»ºçš„å›¾
        if hasattr(cli, 'global_graph_object') and cli.global_graph_object:
            graph = cli.global_graph_object
            print(f"\nğŸ“Š åŸå§‹å›¾ç»Ÿè®¡:")
            print(f"   èŠ‚ç‚¹æ•°: {graph.number_of_nodes()}")
            print(f"   è¾¹æ•°: {graph.number_of_edges()}")
            print(f"   å¯†åº¦: {nx.density(graph):.6f}")
            print(f"   è¿é€šåˆ†é‡æ•°: {nx.number_connected_components(graph)}")
            
            # ç”Ÿæˆä¿®å¤åçš„å¯è§†åŒ–
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = os.path.join(output_dir, f"fixed_visualization_{timestamp}.png")
            
            generate_fixed_visualization(
                graph, 
                output_path, 
                title="Fixed Global Co-occurrence Network",
                seed=42,
                quantile_threshold=0.98
            )
            
            print(f"\nâœ… ä¿®å¤åçš„å¯è§†åŒ–å·²ç”Ÿæˆ:")
            print(f"ğŸ“ è·¯å¾„: {output_path}")
            
        else:
            print("âŒ æœªèƒ½è·å–å›¾å¯¹è±¡")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_fixed_visualization()
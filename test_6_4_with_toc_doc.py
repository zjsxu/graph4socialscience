#!/usr/bin/env python3
"""
ä½¿ç”¨toc_docæ–‡ä»¶å¤¹æµ‹è¯•æ–°çš„6.4åŠŸèƒ½
æµ‹è¯•æ€»å›¾å’Œéšæœºé€‰æ‹©çš„3ä¸ªå­å›¾çš„æ•°æ®å¯¼å‡º
"""

import os
import sys
import time
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, '.')

def test_6_4_with_real_data():
    """ä½¿ç”¨çœŸå®toc_docæ•°æ®æµ‹è¯•6.4åŠŸèƒ½"""
    print("ğŸ§ª ä½¿ç”¨toc_docæ•°æ®æµ‹è¯•6.4åŠŸèƒ½")
    print("=" * 60)
    
    # è®¾ç½®è·¯å¾„
    input_dir = "/Users/zhangjingsen/Desktop/python/graph4socialscience/toc_doc"
    output_dir = "/Users/zhangjingsen/Desktop/python/graph4socialscience/hajimi/haniumoa"
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_dir):
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return False
    
    try:
        # å¯¼å…¥ç®¡é“ç±»
        from complete_usage_guide import ResearchPipelineCLI
        
        # åˆå§‹åŒ–åº”ç”¨
        app = ResearchPipelineCLI()
        app.input_directory = input_dir
        app.output_dir = output_dir
        
        # æ‰«æè¾“å…¥æ–‡ä»¶
        app.input_files = []
        valid_extensions = {'.json', '.txt', '.md'}
        
        for root, dirs, files in os.walk(input_dir):
            for file in files:
                file_path = os.path.join(root, file)
                file_ext = os.path.splitext(file)[1].lower()
                if file_ext in valid_extensions:
                    app.input_files.append(file_path)
        
        app.pipeline_state['data_loaded'] = True
        
        print(f"ğŸ“ è¾“å…¥ç›®å½•: {input_dir}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ“Š æ‰¾åˆ°æ–‡ä»¶: {len(app.input_files)} ä¸ª")
        
        # æ‰§è¡Œå®Œæ•´ç®¡é“
        print("\nğŸ”„ æ‰§è¡Œå®Œæ•´ç®¡é“...")
        
        start_time = time.time()
        
        # 2.1: æ–‡æœ¬æ¸…ç†
        print("2.1 æ–‡æœ¬æ¸…ç†...")
        app.clean_and_normalize_text()
        if not app.pipeline_state['text_cleaned']:
            print("âŒ æ–‡æœ¬æ¸…ç†å¤±è´¥")
            return False
        
        # 3.2: çŸ­è¯­æå–
        print("3.2 çŸ­è¯­æå–...")
        app.extract_tokens_and_phrases()
        if not app.pipeline_state['phrases_constructed']:
            print("âŒ çŸ­è¯­æå–å¤±è´¥")
            return False
        
        # 4.1: å…¨å±€å›¾æ„å»º
        print("4.1 å…¨å±€å›¾æ„å»º...")
        app.build_global_graph()
        if not app.pipeline_state['global_graph_built']:
            print("âŒ å…¨å±€å›¾æ„å»ºå¤±è´¥")
            return False
        
        # 5.1: å­å›¾æ¿€æ´»
        print("5.1 å­å›¾æ¿€æ´»...")
        app.activate_state_subgraphs()
        if not app.pipeline_state['subgraphs_activated']:
            print("âŒ å­å›¾æ¿€æ´»å¤±è´¥")
            return False
        
        # 6.1: å¯è§†åŒ–ç”Ÿæˆ
        print("6.1 å¯è§†åŒ–ç”Ÿæˆ...")
        app.generate_deterministic_visualizations()
        if not hasattr(app, 'visualization_paths') or not app.visualization_paths:
            print("âŒ å¯è§†åŒ–ç”Ÿæˆå¤±è´¥")
            return False
        
        pipeline_time = time.time() - start_time
        print(f"âœ… ç®¡é“æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {pipeline_time:.2f}ç§’")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„å›¾ä¿¡æ¯
        print(f"\nğŸ“Š ç”Ÿæˆçš„å›¾ä¿¡æ¯:")
        print(f"   å…¨å±€å›¾: {app.global_graph_object.number_of_nodes()} èŠ‚ç‚¹, {app.global_graph_object.number_of_edges()} è¾¹")
        
        if hasattr(app, 'state_subgraph_objects'):
            print(f"   å­å›¾æ•°é‡: {len(app.state_subgraph_objects)}")
            for state, subgraph in app.state_subgraph_objects.items():
                print(f"     {state}: {subgraph.number_of_nodes()} èŠ‚ç‚¹, {subgraph.number_of_edges()} è¾¹")
        
        # æµ‹è¯•6.4åŠŸèƒ½ - è‡ªåŠ¨é€‰æ‹©"A"ï¼ˆå…¨éƒ¨å›¾ï¼‰
        print(f"\nğŸ¯ æµ‹è¯•6.4åŠŸèƒ½ï¼šå¯¼å‡ºå›¾æ•°æ®...")
        
        # æ¨¡æ‹Ÿç”¨æˆ·é€‰æ‹©"A"ï¼ˆå…¨éƒ¨å›¾ï¼‰
        original_get_user_choice = app.get_user_choice
        def mock_get_user_choice(prompt, valid_choices):
            print(f"{prompt}: A (è‡ªåŠ¨é€‰æ‹©ï¼šå…¨éƒ¨å›¾)")
            return "A"
        
        app.get_user_choice = mock_get_user_choice
        
        # æ‰§è¡Œ6.4åŠŸèƒ½
        export_start = time.time()
        app.view_graph_nodes_and_data()
        export_time = time.time() - export_start
        
        # æ¢å¤åŸå§‹æ–¹æ³•
        app.get_user_choice = original_get_user_choice
        
        print(f"âœ… 6.4åŠŸèƒ½æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {export_time:.2f}ç§’")
        
        # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
        analysis_dir = os.path.join(output_dir, "graph_analysis")
        if os.path.exists(analysis_dir):
            analysis_files = [f for f in os.listdir(analysis_dir) if f.endswith('.txt')]
            print(f"\nğŸ“„ ç”Ÿæˆçš„åˆ†ææ–‡ä»¶:")
            
            for filename in sorted(analysis_files):
                filepath = os.path.join(analysis_dir, filename)
                file_size = os.path.getsize(filepath)
                print(f"   âœ… {filename} ({file_size} bytes)")
                
                # æ˜¾ç¤ºæ–‡ä»¶å‰å‡ è¡Œå†…å®¹é¢„è§ˆ
                print(f"      é¢„è§ˆ:")
                with open(filepath, 'r', encoding='utf-8') as f:
                    for i, line in enumerate(f):
                        if i >= 5:  # åªæ˜¾ç¤ºå‰5è¡Œ
                            break
                        print(f"        {line.strip()}")
                    print(f"        ...")
                print()
            
            print(f"ğŸ“ æ‰€æœ‰åˆ†ææ–‡ä»¶ä¿å­˜åœ¨: {os.path.abspath(analysis_dir)}")
            
        else:
            print("âŒ æœªæ‰¾åˆ°åˆ†ææ–‡ä»¶ç›®å½•")
            return False
        
        print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ!")
        print(f"âœ… æˆåŠŸä½¿ç”¨toc_docæ•°æ®")
        print(f"âœ… ç”Ÿæˆäº†æ€»å›¾å’Œå­å›¾çš„å®Œæ•´æ•°æ®æ–‡æ¡£")
        print(f"âœ… æ–‡æ¡£åŒ…å«æ‰€æœ‰èŠ‚ç‚¹ã€è¾¹ã€å‚æ•°ä¿¡æ¯")
        
        return True
        
    except Exception as e:
        print(f"ğŸ’¥ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ 6.4åŠŸèƒ½å®é™…æ•°æ®æµ‹è¯•")
    print("ä½¿ç”¨toc_docæ–‡ä»¶å¤¹è¿›è¡Œå®Œæ•´æµ‹è¯•")
    print()
    
    success = test_6_4_with_real_data()
    
    if success:
        print("\nğŸ“‹ æµ‹è¯•ç»“æœ:")
        print("âœ… 6.4åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        print("âœ… èƒ½å¤Ÿå¤„ç†çœŸå®çš„toc_docæ•°æ®")
        print("âœ… æˆåŠŸå¯¼å‡ºå›¾æ•°æ®åˆ°æ–‡æ¡£æ–‡ä»¶")
        print("âœ… æ–‡æ¡£æ ¼å¼æ¸…æ™°ï¼ŒåŒ…å«å®Œæ•´çš„æŠ€æœ¯ä¿¡æ¯")
        print()
        print("ğŸ“„ ç”Ÿæˆçš„æ–‡æ¡£åŒ…å«:")
        print("- å›¾ç»“æ„ä¿¡æ¯ï¼ˆèŠ‚ç‚¹æ•°ã€è¾¹æ•°ã€å¯†åº¦ç­‰ï¼‰")
        print("- å®Œæ•´çš„èŠ‚ç‚¹æ•°æ®ï¼ˆæ‰€æœ‰å±æ€§ï¼‰")
        print("- å®Œæ•´çš„è¾¹æ•°æ®ï¼ˆæ‰€æœ‰å±æ€§ï¼‰")
        print("- å¤„ç†å‚æ•°ï¼ˆå¯é‡ç°æ€§é…ç½®ï¼‰")
        print("- æºæ•°æ®ç»Ÿè®¡")
        print("- çŸ­è¯­æå–æ•°æ®")
        print("- å¸ƒå±€ç®—æ³•å‚æ•°")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥")
    
    return 0 if success else 1

if __name__ == "__main__":
    sys.exit(main())
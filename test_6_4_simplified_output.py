#!/usr/bin/env python3
"""
æµ‹è¯•ç®€åŒ–åçš„6.4åŠŸèƒ½ - ä½¿ç”¨toc_docæ•°æ®
æµ‹è¯•è¾“å‡ºæ ¼å¼æ˜¯å¦ç¬¦åˆç”¨æˆ·è¦æ±‚ï¼šå‡å°‘è§£è¯´æ€§æ–‡å­—ï¼Œç›´æ¥å¯¼å‡ºæŠ€æœ¯æ•°æ®
"""

import os
import sys
import time
from datetime import datetime

def test_6_4_simplified_output():
    """æµ‹è¯•ç®€åŒ–åçš„6.4åŠŸèƒ½è¾“å‡ºæ ¼å¼"""
    print("ğŸ”§ 6.4åŠŸèƒ½ç®€åŒ–è¾“å‡ºæ ¼å¼æµ‹è¯•")
    print("ä½¿ç”¨toc_docæ–‡ä»¶å¤¹è¿›è¡Œå®Œæ•´æµ‹è¯•")
    print()
    
    # è®¾ç½®æµ‹è¯•å‚æ•°
    input_dir = "/Users/zhangjingsen/Desktop/python/graph4socialscience/toc_doc"
    output_dir = "/Users/zhangjingsen/Desktop/python/graph4socialscience/test_6_4_output"
    
    if not os.path.exists(input_dir):
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return
    
    print(f"ğŸ§ª ä½¿ç”¨toc_docæ•°æ®æµ‹è¯•6.4åŠŸèƒ½")
    print("=" * 60)
    
    # å¯¼å…¥ä¸»ç¨‹åº
    try:
        from complete_usage_guide import ResearchPipelineCLI
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºç®¡çº¿å®ä¾‹
    cli = ResearchPipelineCLI()
    
    # è®¾ç½®è¾“å…¥è¾“å‡ºç›®å½•
    cli.input_directory = input_dir
    cli.output_dir = output_dir
    
    # æ‰«æè¾“å…¥æ–‡ä»¶
    print(f"ğŸ“ è¾“å…¥ç›®å½•: {input_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # æ‰«æç›®å½•è·å–æ–‡ä»¶
    cli.input_files = []
    valid_extensions = {'.json', '.txt', '.md'}
    for root, dirs, files in os.walk(input_dir):
        for file in files:
            file_path = os.path.join(root, file)
            file_ext = os.path.splitext(file)[1].lower()
            if file_ext in valid_extensions:
                cli.input_files.append(file_path)
    
    print(f"ğŸ“Š æ‰¾åˆ°æ–‡ä»¶: {len(cli.input_files)} ä¸ª")
    
    if len(cli.input_files) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è¾“å…¥æ–‡ä»¶")
        return
    
    # è®¾ç½®ç®¡çº¿çŠ¶æ€ä¸ºå·²å®Œæˆï¼ˆæ¨¡æ‹Ÿå®Œæ•´æµç¨‹å·²æ‰§è¡Œï¼‰
    cli.pipeline_state = {
        'data_loaded': True,
        'text_cleaned': True,
        'phrases_constructed': True,
        'global_graph_built': True,
        'subgraphs_activated': True,
        'results_exported': True
    }
    
    print("\nğŸ”„ æ‰§è¡Œå®Œæ•´ç®¡é“...")
    
    # æ‰§è¡Œå®Œæ•´ç®¡é“æµç¨‹
    start_time = time.time()
    
    try:
        # 1. æ•°æ®åŠ è½½å’Œæ–‡æœ¬æ¸…ç†
        print("2.1 æ–‡æœ¬æ¸…ç†...")
        cli.clean_and_normalize_text()
        
        # 2. è¯ç»„æå–
        print("3.2 çŸ­è¯­æå–...")
        cli.extract_tokens_and_phrases()
        
        # 3. å…¨å±€å›¾æ„å»º
        print("4.1 å…¨å±€å›¾æ„å»º...")
        cli.build_global_graph()
        
        # 4. å­å›¾æ¿€æ´»
        print("5.1 å­å›¾æ¿€æ´»...")
        cli.activate_state_subgraphs()
        
        # 5. å¯è§†åŒ–ç”Ÿæˆ
        print("6.1 å¯è§†åŒ–ç”Ÿæˆ...")
        cli.generate_deterministic_visualizations()
        
        # 6. æµ‹è¯•6.4åŠŸèƒ½ï¼šå¯¼å‡ºå›¾æ•°æ®
        print("\nğŸ¯ æµ‹è¯•6.4åŠŸèƒ½ï¼šå¯¼å‡ºå›¾æ•°æ®...")
        
        # æ¨¡æ‹Ÿç”¨æˆ·é€‰æ‹©"A"ï¼ˆå…¨éƒ¨å›¾ï¼šæ€»å›¾+3ä¸ªéšæœºå­å›¾ï¼‰
        print("\nğŸ“Š EXPORT GRAPH NODES & DATA DETAILS")
        print("-" * 60)
        print("ğŸ“ˆ Available graphs for analysis:")
        print("0. Global Graph (complete network)")
        
        if hasattr(cli, 'state_subgraph_objects') and cli.state_subgraph_objects:
            for i, (state, subgraph) in enumerate(cli.state_subgraph_objects.items(), 1):
                print(f"{i}. State {state} Subgraph ({subgraph.number_of_nodes()} nodes, {subgraph.number_of_edges()} edges)")
        
        print("A. All graphs (global + 3 random subgraphs)")
        
        print("Select graph to analyze: A (è‡ªåŠ¨é€‰æ‹©ï¼šå…¨éƒ¨å›¾)")
        
        # æ‰§è¡Œ6.4åŠŸèƒ½
        output_dir_analysis = os.path.join(cli.output_dir, "graph_analysis")
        os.makedirs(output_dir_analysis, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # å¯¼å‡ºå…¨å±€å›¾
        if hasattr(cli, 'global_graph_object') and cli.global_graph_object:
            cli._export_single_graph_data(cli.global_graph_object, "global", output_dir_analysis, timestamp)
        
        # å¯¼å‡º3ä¸ªéšæœºå­å›¾
        if hasattr(cli, 'state_subgraph_objects') and cli.state_subgraph_objects:
            import random
            available_subgraphs = list(cli.state_subgraph_objects.items())
            selected_subgraphs = random.sample(available_subgraphs, min(3, len(available_subgraphs)))
            
            for state, subgraph in selected_subgraphs:
                cli._export_single_graph_data(subgraph, f"state_{state}", output_dir_analysis, timestamp)
        
        print(f"âœ… Exported global graph + 3 random subgraphs")
        print(f"ğŸ“ All analysis files saved to: {os.path.abspath(output_dir_analysis)}")
        
        end_time = time.time()
        print(f"âœ… 6.4åŠŸèƒ½æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
        
        # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
        print(f"\nğŸ“„ ç”Ÿæˆçš„åˆ†ææ–‡ä»¶:")
        if os.path.exists(output_dir_analysis):
            analysis_files = [f for f in os.listdir(output_dir_analysis) if f.startswith('graph_data_')]
            for file in sorted(analysis_files):
                file_path = os.path.join(output_dir_analysis, file)
                file_size = os.path.getsize(file_path)
                print(f"   âœ… {file} ({file_size} bytes)")
                
                # æ˜¾ç¤ºæ–‡ä»¶å‰å‡ è¡Œé¢„è§ˆ
                with open(file_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()[:10]
                    preview = ''.join(lines).strip()
                    print(f"      é¢„è§ˆ:")
                    for line in lines[:5]:
                        print(f"        {line.strip()}")
                    print(f"        ...")
                print()
        
        print(f"ğŸ“ æ‰€æœ‰åˆ†ææ–‡ä»¶ä¿å­˜åœ¨: {os.path.abspath(output_dir_analysis)}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆ!")
    print("âœ… æˆåŠŸä½¿ç”¨toc_docæ•°æ®")
    print("âœ… ç”Ÿæˆäº†æ€»å›¾å’Œå­å›¾çš„ç®€åŒ–æ•°æ®æ–‡æ¡£")
    print("âœ… æ–‡æ¡£æ ¼å¼ç®€æ´ï¼Œå‡å°‘äº†è§£è¯´æ€§æ–‡å­—")
    
    print(f"\nğŸ“‹ æµ‹è¯•ç»“æœ:")
    print("âœ… 6.4åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
    print("âœ… èƒ½å¤Ÿå¤„ç†çœŸå®çš„toc_docæ•°æ®")
    print("âœ… æˆåŠŸå¯¼å‡ºç®€åŒ–æ ¼å¼çš„å›¾æ•°æ®åˆ°æ–‡æ¡£æ–‡ä»¶")
    print("âœ… æ–‡æ¡£æ ¼å¼æ¸…æ™°ï¼ŒåŒ…å«å®Œæ•´çš„æŠ€æœ¯ä¿¡æ¯ä½†å‡å°‘å†—ä½™æ–‡å­—")
    
    print(f"\nğŸ“„ ç”Ÿæˆçš„æ–‡æ¡£åŒ…å«:")
    print("- å›¾ç»“æ„ä¿¡æ¯ï¼ˆèŠ‚ç‚¹æ•°ã€è¾¹æ•°ã€å¯†åº¦ç­‰ï¼‰")
    print("- å®Œæ•´çš„èŠ‚ç‚¹æ•°æ®ï¼ˆæ‰€æœ‰å±æ€§ï¼Œè¡¨æ ¼æ ¼å¼ï¼‰")
    print("- å®Œæ•´çš„è¾¹æ•°æ®ï¼ˆæ‰€æœ‰å±æ€§ï¼Œè¡¨æ ¼æ ¼å¼ï¼‰")
    print("- å¤„ç†å‚æ•°ï¼ˆkey=valueæ ¼å¼ï¼‰")
    print("- æºæ•°æ®ç»Ÿè®¡")
    print("- çŸ­è¯­æå–æ•°æ®")
    print("- å¸ƒå±€ç®—æ³•å‚æ•°")

if __name__ == "__main__":
    test_6_4_simplified_output()